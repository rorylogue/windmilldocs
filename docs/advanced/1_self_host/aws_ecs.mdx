---
title: Windmill on AWS ECS
---

Windmill can be deployed on an ECS cluster. Below are the detailed steps to get a Windmill stack up and running. The number of servers and workers, as well as the instance sizes, should be tuned to your own usecases.

To give a brief overview, we will first create a VPC and an associated security group. This VPC will contain the Database, the instances powering the ECS cluster, and the windmill containers. Then we will create a database on RDS, and finally the ECS cluster.
Once the ECS cluster is running, we will define the tasks definitions and the associated services. Note again that the architecture of your Windmill stack very well depends on how you're planning to use Windmill. For this tutorial, we will create a Windmill stack of this shape: 2 windmill servers, 2 "multi-purpose" Windmill workers and 1 "native" worker. Windmill LSP and Multiplayer will also be deployed.

:::tip
Familiar with Terraform? The terraform files are available [here in Windmill's Github repo](https://github.com/windmill-labs/windmill/blob/main/examples/deploy/aws-ecs-terraform/README.md) to deploy this Windmill Stack on ECS with just a few commands!
:::

## Create a VPC and a security group

1. Go to AWS VPC and create a new one.
   - Name: `windmill-vpc`
   - Choose a CIDR block of your choice. We're going to use `10.0.0.0/16` here. Any value will work, just make sure you'll have enough IPs in the CIDR
   - IPv6 is not required
   - We recommend using at least 2 availability zones, with 2 public and 2 private subnets
   - NAT is required for ECS containers to have access to internet. We recommend creating one in each AZ
   - Enable both DNS options
1. You will need a security group linked to this VPC. Go to AWS Security Group menu and create a new one
   - Name: `windmill-sg`
   - Link it to the VPC created above
   - Add the following inbound rule: `All traffic FROM this security group`
   - If you want to SSH into the servers, you might want to add the inbound rule: `SSH from MyIP/Anywhere`. This is not required but might help with debugging
   - Add a rule `HTTP traffic FROM anywhere` to be able to hit Windmill Server from your workstation. You can refine security here by having 2 security groups with only one allowing HTTP traffic. And later you'll place only the server in this security group and all the other containers in the more restricted security group. For simplicity, we will just have one security group here.
   - The default outbound rule can be used: `All traffic TO 0.0.0.0/0`

## Create a RDS database

1. Go to AWS RDS
1. Standard create
1. Engine option:
   - PostgreSQL
   - Any recent version of PostgreSQL will work. At the time of writing we're using 16.1-R1
1. Template
   - Choose the template of your choice (Production VS Dev/Test) depending on your needs. Obviously this will significantly impact costs
1. Availability and durability
   - This will be preset depending on the template option you chose. You can customize it depending on your needs.
1. Settings
   - DB instance identifier: `windmill-db`
   - Leave `postgres` as the username, and choose a strong master password. Keep it in a safe place, you will need it in the following steps
1. Instance configuration
   - The instance type will be preset depending on the template you chose. Default is usually a good starting point
1. Storage. This is on a per-usecase basis. Just be aware that Windmill stores logs and job results in the database. Depending on the job retention period you want to later configure in Windmill, you might have different requirements
   - A good starting point is 400Gib / 12000 IOPS
   - If you chose Multi AZ instance or Standalone instance, it is recommended to turn on autoscaling.
1. Connectivity
   - Don't connect to an EC2 compute resource. Container of the ECS cluster will connect to it using its URL
   - Attach it to the VPC created above
   - The DB doesn't need public access
   - Link it the security group created above
   - RDS proxy can be a good option in certain cases. It is not required
   - We advise to use a certificate authority
   - The port can be left to the default: `5432`
1. Database authentication
   - Windmill uses Password authentication
1. Monitoring
   - Choose whatever you prefer to monitor your database
1. Additional configuration
   - Initial database name should be set to `windmill`
   - It is advised to enable automated backups
   - Encryption can be set depending on your requirement, same for log export and maintenance.

## Create the ECS cluster

As said in the introduction, the architecture of your stack depends of your needs. The only requires parts are one Windmill server at least one multi-purpose worker.

1. Go to AWS ECS and Create a new cluster
1. Cluster configuration
   - Name: `windmill-cluster` and leave the namespace the same
1. Infrastructure
   - Uncheck AWS Fargate and check Amazon EC2 instance
   - Create a new Auto-scaling Group On-Demand
   - Choose Linux as the operating system. We recommend using either default (x86_64) or ARM64 architecture. WARNING: Whichever you choose, make sure the EC2 instance type chose below is matching the OS architecture
   - Choose an EC2 instance type matching the OS above. Here we're using the default Amazon Linux 2 OS, so we will choose a `t3.medium`
   - This Auto-scaling Group will host the 2 Windmill servers, the multi-purpose and native Windmill workers, LSP and multiplayer. The maximum capacity should be at least 6 hosts (5 for the entire load and 1 for rolling updates)
   - Allowing SSH access is not required
   - We recommend allocating at least 100GiB of volume size
1. Network settings for EC2 instances
   - Attach it to the VPC and security group created above
   - The instance can be placed in the private subnets, we will access them through a load balancer

## Create a Load Balancer and Target Groups

We're going to create 3 target groups, for the Windmill server, LSP and Multiplayer

1. Go to Target Groups and create a new one
   - Target type: IP addresses
   - Target group name: `windmill-cluster-server-tg`
   - Protocol: HTTP / Port 8000
   - Attach it to the VPC created above
   - Protocol Version: HTTP1
   - No need to add explicit IP targets right now. The ECS services will register themselves automatically
1. Do the same for LSP
   - Same steps as above but with name: `windmill-cluster-lsp-tg` and port: `3001`
1. Do the same for Multiplayer
   - Same steps as above but with name: `windmill-cluster-multip-tg` and port: `3002`

Now create a Load balancer:

1. Create a new Application Load Balancer
   - Name: `windmill-cluster-alb`
   - It must be internet facing
   - IP address type: IPv4
   - Network mapping: select the VPC created above and map it to the 2 public subnets
   - Security group: Select the security group created above
   - Listener: Default listener on port 80 / Foward to the Target Group `windmill-cluster-server-tg`
   - Click on Create
1. Once the ALB is created, go to its page to add rules for LSP and Multiplayer
   - Select the Listener `HTTP:80` and click on Manage rule > Add Rule
1. Add a Route for LSP
   - Name: `lsp`
   - Add a condition: `Path is /ws/*`
   - Click Next
   - Select target group `windmill-lsp-tg`
   - Give it a priority of `10`
   - Click on Create
1. Add a group for Multiplayer
   - Same steps as for LSP above
   - The path should be `/ws_mp/*`
   - The target group should be `windmill-multiplayer-tg`

## Create the task definitions

We will create 6 tasks definitions here:

- _REQUIRED_ For Windmill Server
- _REQUIRED_ For multi-purpose Windmill workers
- _OPTIONAL_ For native Windmill workers
- _OPTIONAL_ For Windmill LSP
- _OPTIONAL_ For Windmill Multiplayer

#### Windmill Server

1. Name: `windmill-server`
1. Launch Type: AWS EC2 instances
1. OS / Arch: Linux/x86_64 (to match the EC2 instance type and OS architecture)
1. Network mode: `awsvpc`. This will virtually attach the containers to the VPC networks. The NAT of the VPC is required to give internet access to the containers.
1. Task Size: 1vCPU / 1.5GiB Memory (this is for a cluster of 6 `t3.medium`. Adapt it to the hardware you provisioned)
1. Task Role: None
1. No Task placement
1. Container:
   - name: `windmill-server`
   - image: `ghcr.io/windmill-labs/windmill:main` (or `ghcr.io/windmill-labs/windmill-ee:main` for EE)
   - Essential container: YES
   - Port mapping: 8000 / TCP / http / HTTP
   - Resource allocation: 1 CPU / 1.5 GiB memory
   - Environment variable: `JSON_FMT=true`, `MODE=server` and `DATABASE_URL=postgres://postgres:<DB_PASSWORD>@<DB_HOSTNAME>:5432/windmill`. Replace the hostname and password with the ones from the RDS database your created above
   - Turn on log collection for easy debugging
   - Add the following health check: `CMD-SHELL, curl -f http://localhost:8000/api/version || exit 1` / 10s interval / 5s timeout and 5 retries
   - Leave the rest default

#### Windmill multi-purpose worker

1. Name: `windmill-worker`
1. Launch Type: AWS EC2 instances
1. OS / Arch: Linux/x86_64 (to match the EC2 instance type and OS architecture)
1. Network mode: `awsvpc`
1. Task Size: 2vCPU / 3.5GiB Memory (this is for a cluster of 6 `t3.medium`. Adapt it to the hardware you provisioned)
1. Task Role: None
1. No Task placement
1. Container:
   - name: `windmill-worker`
   - image: `ghcr.io/windmill-labs/windmill:main` (or `ghcr.io/windmill-labs/windmill-ee:main` for EE)
   - Essential container: YES
   - Port mapping: No port mapping for workers
   - Resource allocation: 2 CPU / 3.5 GiB memory
   - Environment variable: `JSON_FMT=true`, `MODE=worker`, `WORKER_GROUP=default` and `DATABASE_URL=postgres://postgres:<DB_PASSWORD>@<DB_HOSTNAME>:5432/windmill`
   - Add a Bind volume named `worker_dependency_cache` mapped to `/tmp/windmill/cache`
   - Turn on log collection for easy debugging
   - This is it, leave the rest default

#### Windmill native worker

1. Name: `windmill-native-worker`
1. Launch Type: AWS EC2 instances
1. OS / Arch: Linux/x86_64 (to match the EC2 instance type and OS architecture)
1. Network mode: `awsvpc`
1. Task Size: 2vCPU / 3.5GiB Memory (this is for a cluster of 6 `t3.medium`. Adapt it to the hardware you provisioned)
1. Task Role: None
1. No Task placement
1. Container:
   - name: `windmill-worker`
   - image: `ghcr.io/windmill-labs/windmill:main` (or `ghcr.io/windmill-labs/windmill-ee:main` for EE)
   - Essential container: YES
   - Port mapping: no port mapping for workers
   - Resource allocation: 2 CPU / 3.5 GiB memory
   - Environment variable: `JSON_FMT=true`, `MODE=worker`, `WORKER_GROUP=native` and `DATABASE_URL=postgres://postgres:<DB_PASSWORD>@<DB_HOSTNAME>:5432/windmill`
   - Add a Bind volume named `worker_dependency_cache` mapped to `/tmp/windmill/cache`
   - Turn on log collection for easy debugging
   - This is it, leave the rest default

#### Windmill LSP

1. Name: `windmill-lsp`
1. Launch Type: AWS EC2 instances
1. OS / Arch: Linux/x86_64 (to match the EC2 instance type and OS architecture)
1. Network mode: `awsvpc`
1. Task Size: 1vCPU / 1.5GiB Memory (this is for a cluster of 6 `t3.medium`. Adapt it to the hardware you provisioned)
1. Task Role: None
1. No Task placement
1. Container:
   - name: `windmill-lsp`
   - image: `ghcr.io/windmill-labs/windmill-lsp:latest`
   - Essential container: YES
   - Port mapping: 3001 / TCP / http / HTTP
   - Resource allocation: 1 CPU / 1.5 GiB memory
   - Environment variable: `JSON_FMT=true`,
   - Add a Bind volume named `lsp_cache` mapped to `/root/.cache`
   - Turn on log collection for easy debugging
   - This is it, leave the rest default

#### Windmill Multiplayer

1. Name: `windmill-multiplayer`
1. Launch Type: AWS EC2 instances
1. OS / Arch: Linux/x86_64 (to match the EC2 instance type and OS architecture)
1. Network mode: `awsvpc`
1. Task Size: 1vCPU / 1.5GiB Memory (this is for a cluster of 6 `t3.medium`. Adapt it to the hardware you provisioned)
1. Task Role: None
1. No Task placement
1. Container:
   - name: `windmill-multiplayer`
   - image: `ghcr.io/windmill-labs/windmill-multiplayer:latest`
   - Essential container: YES
   - Port mapping: 3002 / TCP / http / HTTP
   - Resource allocation: 1 CPU / 1.5 GiB memory
   - Environment variable: `JSON_FMT=true`
   - Turn on log collection for easy debugging
   - This is it, leave the rest default

## Create the services

One for each task definition, we now will create 6 services.

#### Windmill server

1. Environment: leave everything default. It will be using the default capacity provider
1. Application type: Service
1. Task definition: select the latest revision of the `windmill-server` task
1. Service name: `windmill-server`
1. Service replica: 2 (to follow the architecture we presented above)
1. Networking: Select the VPC created above, and place the services in the PUBLIC subnets. Select the security group created above (or the one allowing traffic on port 80)
1. Load balancer: Link it to the load balancer created above with the target group `windmill-cluster-server-tg`

#### Multi-purpose Windmill worker

1. Environment: leave everything default. It will be using the default capacity provider
1. Application type: Service
1. Task definition: select the latest revision of the `windmill-worker` task
1. Service name: `windmill-worker`
1. Service replica: 2 (to follow the architecture we presented above)
1. Networking: Select the VPC created above, and place the services in the PRIVATE subnets. No need for workers to be in the public subnets, as there's NAT in the VPC. Select the security group created above
1. Load balancer: No load balancer, the container is not exposing any port

#### Native Windmill Worker

1. Same a the multi-purpose Windmill worker, except that the task definition should be `windmill-native-worker`

#### Windmill LSP

1. Environment: leave everything default. It will be using the default capacity provider
1. Application type: Service
1. Task definition: select the latest revision of the `windmill-lsp` task
1. Service name: `windmill-lsp`
1. Service replica: 1
1. Networking: Select the VPC created above, and place the services in the PUBLIC subnets. Select the security group created above
1. Load balancer: Link it to the load balancer created above with the target group `windmill-cluster-lsp-tg`

#### Windmill Multiplayer

1. Same as Windmill LSP, using the task definition `windmill-native-worker`.

## Open Windmill

Go back to the `windmill-server-lb` and copy its DNS. Open it in a new tab. You should see the Windmill Login interface. Follow the instructions to go through the initial Windmill setup
